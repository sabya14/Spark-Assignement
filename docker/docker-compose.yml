version: '2.2'
services:
  spark-master:
    image: bde2020/spark-master:2.4.5-hadoop2.7
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    volumes:
      - ../data:/data

  spark-worker-1:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    volumes:
      - ../data:/data

  spark-worker-2:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    volumes:
      - ../data:/data

  data-cohort:
    build:
      context: ../
      dockerfile: docker/Dockerfile
    container_name: cohort-job
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
    environment:
      ENABLE_INIT_DAEMON: "false"
      SPARK_APPLICATION_MAIN_CLASS: ride_info.cohort.Runner
      SPARK_APPLICATION_ARGS: "/data/ct_rr.csv 2018-04-07 10 /data/output.csv"
    volumes:
     - ../data:/data

  data-aggregate:
    build:
      context: ../
      dockerfile: docker/Dockerfile
    container_name: data-aggregate
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
    environment:
      ENABLE_INIT_DAEMON: "false"
      SPARK_APPLICATION_MAIN_CLASS: ride_info.aggregator.Runner
      SPARK_APPLICATION_ARGS: "/data/ct_rr.csv /data/outputAggregator.csv"
    volumes:
      - ../data:/data
